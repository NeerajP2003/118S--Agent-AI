{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8pcGWOPstsl8dTP2v48hq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeerajP2003/118S--Agent-AI/blob/main/Coding_Exercise_ML_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ],
      "metadata": {
        "id": "KIzV5UVXpfKY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_62x2p1q0He",
        "outputId": "f096a470-d34a-40ef-8fbc-e8a3717e979d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price for a 2000 sq ft house in Downtown: $1,251,640.86\n",
            "\n",
            "Model Coefficients:\n",
            "location_Downtown: -71605.38\n",
            "location_Rural: 82581.35\n",
            "location_Suburb: -10975.97\n",
            "square_footage: 20.05\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate sample data from chatgpt\n",
        "num_data_points = 100 # Set the desired number of data points\n",
        "\n",
        "data = {\n",
        "'square_footage': np.random.randint(500, 5000, size=num_data_points),\n",
        "'location': np.random.choice(['Downtown', 'Suburb', 'Downtown', 'Rural'], size = num_data_points),\n",
        "'price': np.random.randint(750000, 2000000, size = num_data_points),\n",
        "  }\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features and target\n",
        "X = df[['square_footage', 'location']]\n",
        "y = df['price']\n",
        "\n",
        "# Preprocessing: One-hot encode the location column\n",
        "preprocessor = ColumnTransformer(\n",
        "transformers=[\n",
        "('location', OneHotEncoder(sparse_output=False), ['location'])\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create pipeline with preprocessing and model\n",
        "model = Pipeline(steps=[\n",
        "('preprocessor', preprocessor),\n",
        "('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction for a new house: 2000 sq ft in dowtown\n",
        "new_house = pd.DataFrame({'square_footage': [2000], 'location': ['Downtown']})\n",
        "predicted_price = model.predict(new_house)\n",
        "print(f\"Predicted price for a 2000 sq ft house in Downtown: ${predicted_price[0]:,.2f}\")\n",
        "\n",
        "# Display model coefficients\n",
        "feature_names = (model.named_steps['preprocessor'].named_transformers_['location'].get_feature_names_out(['location'])).tolist() + ['square_footage']\n",
        "coefficients = model.named_steps['regressor'].coef_\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for feature, coef in zip(feature_names, coefficients):\n",
        "    print(f\"{feature}: {coef:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ],
      "metadata": {
        "id": "86PuxuNqqSMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Generate customer data from chatgpt\n",
        "np.random.seed(50)\n",
        "sample_size = np.random.randint(100, 500)\n",
        "\n",
        "# Generate sample customer data\n",
        "data = {\n",
        "'age': np.random.randint(30,75, size = sample_size),\n",
        "'monthly_usage_hours': np.random.randint(50, 500, size = sample_size),\n",
        "'purchase_amount': np.random.randint(10000, 50000, size = sample_size),\n",
        "'customer_service_calls': np.random.randint(0, 100, size = sample_size),\n",
        "'region': np.random.choice(['North', 'South', 'West', 'East'],size = sample_size),\n",
        "'churn':  np.random.randint(0,2,size = sample_size), # 1 = churned, 0 = not churned\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features and target\n",
        "X = df[['age', 'monthly_usage_hours', 'purchase_amount', 'customer_service_calls',\n",
        "'region']]\n",
        "y = df['churn']\n",
        "\n",
        "# Preprocessing: Scale numerical features and one-hot encode categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "transformers=[\n",
        "('num', StandardScaler(), ['age', 'monthly_usage_hours', 'purchase_amount',\n",
        "'customer_service_calls']),\n",
        "('cat', OneHotEncoder(sparse_output=False), ['region'])\n",
        "])\n",
        "\n",
        "# Create pipeline with preprocessing and model\n",
        "model = Pipeline(steps=[\n",
        "('preprocessor', preprocessor),\n",
        "('classifier', LogisticRegression(random_state=42))\n",
        "])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict churn probability for a new customer\n",
        "new_customer = pd.DataFrame({\n",
        "'age': [35],\n",
        "'monthly_usage_hours': [20],\n",
        "'purchase_amount': [150],\n",
        "'customer_service_calls': [5],\n",
        "'region': ['West']\n",
        "})\n",
        "churn_probability = model.predict_proba(new_customer)[0][1] # Probability of churn\n",
        "\n",
        "# Classify based on threshold (0.5)\n",
        "threshold = 0.5\n",
        "churn_prediction = 1 if churn_probability > threshold else 0\n",
        "\n",
        "print(f\"Churn Probability for new customer: {churn_probability:.2f}\")\n",
        "print(f\"Churn Prediction (1 = churn, 0 = no churn): {churn_prediction}\")\n",
        "\n",
        "# Display model coefficients\n",
        "feature_names = (model.named_steps['preprocessor']\n",
        ".named_transformers_['cat']\n",
        ".get_feature_names_out(['region'])).tolist() + ['age',\n",
        "'monthly_usage_hours', 'purchase_amount', 'customer_service_calls']\n",
        "coefficients = model.named_steps['classifier'].coef_[0]\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for feature, coef in zip(feature_names, coefficients):\n",
        "    print(f\"{feature}: {coef:.2f}\")"
      ],
      "metadata": {
        "id": "d0jmn_3VqVCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad50b83-4dca-48cd-dae3-1540cbfdab4d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Churn Probability for new customer: 0.56\n",
            "Churn Prediction (1 = churn, 0 = no churn): 1\n",
            "\n",
            "Model Coefficients:\n",
            "region_East: 0.01\n",
            "region_North: 0.06\n",
            "region_South: -0.06\n",
            "region_West: -0.10\n",
            "age: 0.19\n",
            "monthly_usage_hours: -0.28\n",
            "purchase_amount: -0.14\n",
            "customer_service_calls: 0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3"
      ],
      "metadata": {
        "id": "xMR-lztjqlI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample customer data from chatgpt\n",
        "data = {\n",
        "'annual_spending': np.random.randint(10000, 40000, size = sample_size),\n",
        "'purchase_frequency': np.random.randint(100, 2000, size = sample_size),\n",
        "'age': np.random.randint(30,75, size = sample_size) ,\n",
        "'region': np.random.choice(['North', 'South', 'West', 'East'], size = sample_size)\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "# Preprocess data: Select numerical features and scale them\n",
        "features = ['annual_spending', 'purchase_frequency', 'age']\n",
        "X = df[features]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Determine optimal number of clusters using elbow method\n",
        "inertia = []\n",
        "K = range(1, 6)\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "# Plot elbow curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(K, inertia, 'bo-')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.savefig('elbow_plot.png')\n",
        "plt.close()\n",
        "# Apply K-Means with optimal K (e.g., 3 based on elbow method)\n",
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "# Analyze clusters\n",
        "cluster_summary = df.groupby('cluster')[features].mean().round(2)\n",
        "print(\"Cluster Characteristics:\")\n",
        "print(cluster_summary)\n",
        "# Example of targeted strategies\n",
        "for cluster in range(optimal_k):\n",
        "    print(f\"\\nCluster {cluster} Strategy:\")\n",
        "    if cluster_summary.loc[cluster, 'annual_spending'] > 1000:\n",
        "        print(\"High-spending customers: Offer exclusive promotions or loyalty rewards.\")\n",
        "    elif cluster_summary.loc[cluster, 'purchase_frequency'] > 10:\n",
        "        print(\"Frequent buyers: Provide bulk discounts or subscription plans.\")\n",
        "    else:\n",
        "        print(\"Low-engagement customers: Send personalized re-engagement campaigns.\")\n",
        "# Save cluster assignments to CSV\n",
        "df.to_csv('customer_segments.csv', index=False)"
      ],
      "metadata": {
        "id": "BCQ6VuTnbaHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9bd4af9-3b11-4a0f-cfea-64ae8a91cbaf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Characteristics:\n",
            "         annual_spending  purchase_frequency    age\n",
            "cluster                                            \n",
            "0               24483.64              595.24  40.72\n",
            "1               26277.97             1602.85  51.70\n",
            "2               22717.01              804.86  65.36\n",
            "\n",
            "Cluster 0 Strategy:\n",
            "High-spending customers: Offer exclusive promotions or loyalty rewards.\n",
            "\n",
            "Cluster 1 Strategy:\n",
            "High-spending customers: Offer exclusive promotions or loyalty rewards.\n",
            "\n",
            "Cluster 2 Strategy:\n",
            "High-spending customers: Offer exclusive promotions or loyalty rewards.\n"
          ]
        }
      ]
    }
  ]
}